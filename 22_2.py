# train_lightgbm_optuna.py

import pandas as pd
import numpy as np
import joblib
import optuna

from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import roc_auc_score, accuracy_score
import lightgbm as lgb
from imblearn.over_sampling import SMOTE
from sklearn.feature_selection import SelectFromModel

import warnings
warnings.filterwarnings("ignore")

########################################
# 0) ê³µí†µ ì „ì²˜ë¦¬ì— ì“°ì¼ í•¨ìˆ˜ ë° ë§¤í•‘
########################################
age_map_surgery = {
    "ë§Œ18-34ì„¸": 26,
    "ë§Œ35-37ì„¸": 36,
    "ë§Œ38-39ì„¸": 38,
    "ë§Œ38-40ì„¸": 39,
    "ë§Œ40-42ì„¸": 41,
    "ë§Œ43-44ì„¸": 43,
    "ë§Œ45-50ì„¸": 47,
    "ì•Œ_ìˆ˜_ì—†ìŒ": np.nan  # ê³µë°± ì¹˜í™˜
}
age_map_donor = {
    "ë§Œ20ì„¸_ì´í•˜": 20,
    "ë§Œ21-25ì„¸": 23,
    "ë§Œ26-30ì„¸": 28,
    "ë§Œ31-35ì„¸": 33,
    "ë§Œ36-40ì„¸": 38,
    "ë§Œ41-45ì„¸": 43,
    "ì•Œ_ìˆ˜_ì—†ìŒ": np.nan
}

def parse_age_surgery(x):
    return age_map_surgery.get(str(x).strip(), np.nan)

def parse_age_donor(x):
    return age_map_donor.get(str(x).strip(), np.nan)

def parse_cycle_count(x):
    if isinstance(x, str):
        if "ì´ìƒ" in x:
            return 6
        elif "íšŒ" in x:
            return pd.to_numeric(x.replace("íšŒ", ""), errors="coerce")
    return pd.to_numeric(x, errors="coerce")

def parse_bool(x):
    if pd.isna(x):
        return -1
    if isinstance(x, str):
        lx = x.strip().lower()
        if lx in ["true", "1"]:
            return 1
        elif lx in ["false", "0"]:
            return 0
        else:
            return -1
    val = pd.to_numeric(x, errors="coerce")
    if pd.isna(val):
        return -1
    return 1 if val == 1 else 0

################################
# 1) í•™ìŠµ(Training) ì‹¤í–‰ ë¶€ë¶„
################################
if __name__ == "__main__":
    # (A) ë°ì´í„° ë¡œë“œ
    train = pd.read_csv("./0_rawdataset/train.csv")

    # ê³µë°± ì»¬ëŸ¼ëª… â†’ ë°‘ì¤„ ì¹˜í™˜
    train.columns = [c.replace(" ", "_") for c in train.columns]

    # ID ì œê±°(ìˆë‹¤ë©´)
    if "ID" in train.columns:
        train.drop(columns=["ID"], inplace=True)

    # íƒ€ê²Ÿ ì§€ì •
    target_col = "ì„ì‹ _ì„±ê³µ_ì—¬ë¶€"
    if train[target_col].dtype == object:
        train[target_col] = train[target_col].apply(lambda v: 1 if str(v).strip() == "1" else 0)

    # (B) ì „ì²˜ë¦¬
    label_encoders = {}

    # ì‹œìˆ  ì‹œê¸° ì½”ë“œ
    code_col = "ì‹œìˆ _ì‹œê¸°_ì½”ë“œ"
    if code_col in train.columns:
        train[code_col].fillna("missing", inplace=True)
        le_code = LabelEncoder()
        train[code_col] = le_code.fit_transform(train[code_col].astype(str))
        label_encoders[code_col] = le_code

    # ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´
    if "ì‹œìˆ _ë‹¹ì‹œ_ë‚˜ì´" in train.columns:
        train["ì‹œìˆ _ë‹¹ì‹œ_ë‚˜ì´"] = train["ì‹œìˆ _ë‹¹ì‹œ_ë‚˜ì´"].apply(parse_age_surgery)

    # ì‚¬ì´í´(0íšŒ~6íšŒì´ìƒ)
    cycle_cols = [
        "ì´_ì‹œìˆ _íšŸìˆ˜","í´ë¦¬ë‹‰_ë‚´_ì´_ì‹œìˆ _íšŸìˆ˜","IVF_ì‹œìˆ _íšŸìˆ˜","DI_ì‹œìˆ _íšŸìˆ˜",
        "ì´_ì„ì‹ _íšŸìˆ˜","IVF_ì„ì‹ _íšŸìˆ˜","DI_ì„ì‹ _íšŸìˆ˜","ì´_ì¶œì‚°_íšŸìˆ˜","IVF_ì¶œì‚°_íšŸìˆ˜","DI_ì¶œì‚°_íšŸìˆ˜"
    ]
    for c in cycle_cols:
        if c in train.columns:
            train[c] = train[c].apply(parse_cycle_count)

    # bool ì»¬ëŸ¼
    bool_cols = [
        "ë‹¨ì¼_ë°°ì•„_ì´ì‹_ì—¬ë¶€","ì°©ìƒ_ì „_ìœ ì „_ê²€ì‚¬_ì‚¬ìš©_ì—¬ë¶€","ì°©ìƒ_ì „_ìœ ì „_ì§„ë‹¨_ì‚¬ìš©_ì—¬ë¶€",
        "ë™ê²°_ë°°ì•„_ì‚¬ìš©_ì—¬ë¶€","ì‹ ì„ _ë°°ì•„_ì‚¬ìš©_ì—¬ë¶€","ê¸°ì¦_ë°°ì•„_ì‚¬ìš©_ì—¬ë¶€","ëŒ€ë¦¬ëª¨_ì—¬ë¶€",
        "PGD_ì‹œìˆ _ì—¬ë¶€","PGS_ì‹œìˆ _ì—¬ë¶€",
        "ë‚¨ì„±_ì£¼_ë¶ˆì„_ì›ì¸","ë‚¨ì„±_ë¶€_ë¶ˆì„_ì›ì¸","ì—¬ì„±_ì£¼_ë¶ˆì„_ì›ì¸","ì—¬ì„±_ë¶€_ë¶ˆì„_ì›ì¸","ë¶€ë¶€_ì£¼_ë¶ˆì„_ì›ì¸",
        "ë¶€ë¶€_ë¶€_ë¶ˆì„_ì›ì¸","ë¶ˆëª…í™•_ë¶ˆì„_ì›ì¸","ë¶ˆì„_ì›ì¸_-_ë‚œê´€_ì§ˆí™˜","ë¶ˆì„_ì›ì¸_-_ë‚¨ì„±_ìš”ì¸",
        "ë¶ˆì„_ì›ì¸_-_ë°°ë€_ì¥ì• ","ë¶ˆì„_ì›ì¸_-_ì—¬ì„±_ìš”ì¸","ë¶ˆì„_ì›ì¸_-_ìê¶ê²½ë¶€_ë¬¸ì œ","ë¶ˆì„_ì›ì¸_-_ìê¶ë‚´ë§‰ì¦",
        "ë¶ˆì„_ì›ì¸_-_ì •ì_ë†ë„","ë¶ˆì„_ì›ì¸_-_ì •ì_ë©´ì—­í•™ì _ìš”ì¸","ë¶ˆì„_ì›ì¸_-_ì •ì_ìš´ë™ì„±","ë¶ˆì„_ì›ì¸_-_ì •ì_í˜•íƒœ"
    ]
    for c in bool_cols:
        if c in train.columns:
            train[c] = train[c].apply(parse_bool)

    # ë²”ì£¼í˜•
    cat_cols = [
        "ì‹œìˆ _ìœ í˜•","íŠ¹ì •_ì‹œìˆ _ìœ í˜•","ë°°ë€_ìœ ë„_ìœ í˜•","ë°°ì•„_ìƒì„±_ì£¼ìš”_ì´ìœ ","ë‚œì_ì¶œì²˜","ì •ì_ì¶œì²˜"
    ]
    for c in cat_cols:
        if c in train.columns:
            train[c].fillna("missing", inplace=True)
            le_tmp = LabelEncoder()
            train[c] = le_tmp.fit_transform(train[c].astype(str))
            label_encoders[c] = le_tmp

    # ë‚œì ê¸°ì¦ì ë‚˜ì´, ì •ì ê¸°ì¦ì ë‚˜ì´
    if "ë‚œì_ê¸°ì¦ì_ë‚˜ì´" in train.columns:
        train["ë‚œì_ê¸°ì¦ì_ë‚˜ì´"] = train["ë‚œì_ê¸°ì¦ì_ë‚˜ì´"].apply(parse_age_donor)
    if "ì •ì_ê¸°ì¦ì_ë‚˜ì´" in train.columns:
        train["ì •ì_ê¸°ì¦ì_ë‚˜ì´"] = train["ì •ì_ê¸°ì¦ì_ë‚˜ì´"].apply(parse_age_donor)

    # â–¼â–¼â–¼ ê²½ê³¼ì¼ ì»¬ëŸ¼ ì¶”ê°€ ë³´ì™„ â–¼â–¼â–¼
    day_cols = [
        "ë‚œì_ì±„ì·¨_ê²½ê³¼ì¼","ë‚œì_í•´ë™_ê²½ê³¼ì¼","ë‚œì_í˜¼í•©_ê²½ê³¼ì¼","ë°°ì•„_ì´ì‹_ê²½ê³¼ì¼","ë°°ì•„_í•´ë™_ê²½ê³¼ì¼"
    ]
    for c in day_cols:
        if c in train.columns:
            train[c] = pd.to_numeric(train[c], errors="coerce")
            # ì¶”ê°€ë¡œ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ or ì´ìƒì¹˜ ì œê±°
            train[c].fillna(-1, inplace=True)
            # í•„ìš”í•˜ë‹¤ë©´ np.clip ë“±ë„ ê°€ëŠ¥

    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    if "ì‹œìˆ _ë‹¹ì‹œ_ë‚˜ì´" in train.columns:
        median_val = train["ì‹œìˆ _ë‹¹ì‹œ_ë‚˜ì´"].median()
        train["ì‹œìˆ _ë‹¹ì‹œ_ë‚˜ì´"].fillna(median_val, inplace=True)
    train.fillna(-1, inplace=True)

    # íŒŒìƒ ë³€ìˆ˜
    if "ì´_ìƒì„±_ë°°ì•„_ìˆ˜" in train.columns and "ì´ì‹ëœ_ë°°ì•„_ìˆ˜" in train.columns:
        train["ë°°ì•„_ì´ì‹_ë¹„ìœ¨"] = np.where(
            train["ì´_ìƒì„±_ë°°ì•„_ìˆ˜"] == 0,
            0,
            train["ì´ì‹ëœ_ë°°ì•„_ìˆ˜"] / train["ì´_ìƒì„±_ë°°ì•„_ìˆ˜"]
        )

    # ì´ìƒì¹˜ ì œê±° (ë‚˜ì´ 15~60)
    if "ì‹œìˆ _ë‹¹ì‹œ_ë‚˜ì´" in train.columns:
        train = train[(train["ì‹œìˆ _ë‹¹ì‹œ_ë‚˜ì´"]>=15) & (train["ì‹œìˆ _ë‹¹ì‹œ_ë‚˜ì´"]<=60)]

    # (C) X, y ë¶„ë¦¬ & Feature Selection
    X = train.drop(columns=[target_col])
    y = train[target_col]

    selector_model = lgb.LGBMClassifier(n_estimators=300, learning_rate=0.05, random_state=42)
    selector_model.fit(X, y)

    from sklearn.feature_selection import SelectFromModel
    selector = SelectFromModel(selector_model, threshold="median", prefit=True)
    selected_features = X.columns[selector.get_support()]
    X_selected = X[selected_features].copy()

    X_selected.replace([np.inf, -np.inf], np.nan, inplace=True)
    X_selected.dropna(inplace=True)
    y = y.loc[X_selected.index]

    X_selected = X_selected.astype(np.float32)
    y = y.astype(int)

    # SMOTE
    smote = SMOTE(random_state=42)
    X_resampled, y_resampled = smote.fit_resample(X_selected, y)

    # ìŠ¤ì¼€ì¼ëŸ¬
    scaler = StandardScaler()
    X_resampled = scaler.fit_transform(X_resampled)

    # (D) Optunaë¡œ LGBM í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
    import optuna
    from sklearn.model_selection import StratifiedKFold
    def objective(trial):
        param = {
            "boosting_type": "gbdt",
            "objective": "binary",
            "metric": "auc",
            "random_state": 42,
            "learning_rate": trial.suggest_float("learning_rate", 0.005, 0.1, log=True),
            "n_estimators": trial.suggest_int("n_estimators", 300, 2000),
            "num_leaves": trial.suggest_int("num_leaves", 15, 255),
            "max_depth": trial.suggest_int("max_depth", 3, 12),
            "min_child_samples": trial.suggest_int("min_child_samples", 10, 200),
            "min_split_gain": trial.suggest_float("min_split_gain", 0.0, 1.0),
            "reg_alpha": trial.suggest_float("reg_alpha", 0.0, 2.0),
            "reg_lambda": trial.suggest_float("reg_lambda", 0.0, 2.0),
            "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
            "subsample": trial.suggest_float("subsample", 0.5, 1.0),
            "bagging_freq": trial.suggest_int("bagging_freq", 1, 10),
            "max_bin": trial.suggest_int("max_bin", 63, 255),
            "extra_trees": trial.suggest_categorical("extra_trees", [False, True])
        }

        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
        auc_scores = []
        for train_idx, val_idx in cv.split(X_resampled, y_resampled):
            X_train, X_val = X_resampled[train_idx], X_resampled[val_idx]
            y_train, y_val = y_resampled[train_idx], y_resampled[val_idx]
            model = lgb.LGBMClassifier(**param)
            model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                eval_metric="auc",
                callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(-1)]
            )
            preds = model.predict_proba(X_val)[:, 1]
            auc_scores.append(roc_auc_score(y_val, preds))
        return np.mean(auc_scores)

    study = optuna.create_study(direction="maximize")
    study.optimize(objective, n_trials=50)
    print("âœ… Best trial:", study.best_trial)
    best_params = study.best_trial.params
    print("âœ… ìµœì  íŒŒë¼ë¯¸í„°:", best_params)

    # ìµœì¢… ëª¨ë¸ í•™ìŠµ
    best_params.update({
        "boosting_type": "gbdt",
        "objective": "binary",
        "metric": "auc",
        "random_state": 42
    })
    best_lgb_model = lgb.LGBMClassifier(**best_params)
    best_lgb_model.fit(X_resampled, y_resampled, callbacks=[lgb.log_evaluation(-1)])

    # í•™ìŠµ ë°ì´í„° ì„±ëŠ¥
    from sklearn.metrics import accuracy_score
    train_preds = best_lgb_model.predict_proba(X_resampled)[:,1]
    train_pred_class = (train_preds >= 0.5).astype(int)
    from sklearn.metrics import roc_auc_score
    train_acc = accuracy_score(y_resampled, train_pred_class)
    train_auc = roc_auc_score(y_resampled, train_preds)
    print("ğŸ”¥ Train Accuracy:", f"{train_acc:.4f}")
    print("ğŸ”¥ Train ROC-AUC:", f"{train_auc:.4f}")

    # (E) ì €ì¥: ëª¨ë¸, ìŠ¤ì¼€ì¼ëŸ¬, í”¼ì²˜ ëª©ë¡, ë¼ë²¨ ì¸ì½”ë” dict
    joblib.dump(best_lgb_model, "22-best_lgb_model.pkl")
    joblib.dump(scaler, "22-scaler.pkl")
    joblib.dump(list(selected_features), "22-train_features.pkl")
    joblib.dump(label_encoders, "22-label_encoders.pkl")
    print("âœ… ëª¨ë“  ê°ì²´ ì €ì¥ ì™„ë£Œ (ê²½ê³¼ì¼ ì²˜ë¦¬ í¬í•¨)")
